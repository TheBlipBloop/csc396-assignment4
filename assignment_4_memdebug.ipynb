{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216965d0-503f-4267-9420-ee2cb6c130e8",
   "metadata": {},
   "source": [
    "# Assignment 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e382b",
   "metadata": {},
   "source": [
    "This notebook uses Roberta to generate static embeddings for words with 768d averaged contextual embeddings. Contextual embeddings are calculated using the provided `dataset.txt`. Ensure the file `dataset.txt` is placed in the directory as this notebook before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2746e-2836-44b9-8422-33ad1d30d0b7",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f874bd9-a81e-419a-9ee5-2731ef1cafd1",
   "metadata": {},
   "source": [
    "Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d805de2-295a-485c-abeb-d253c9c7e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import psutil\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import RobertaModel, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70527ac9-3e10-41d0-8ffa-03eefbe50ffd",
   "metadata": {},
   "source": [
    "Initialize environment compute device (GPU or CPU depending on whats avalible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e09e291-92dd-4179-9ded-72c95279a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551ea27",
   "metadata": {},
   "source": [
    "Initalize global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf3b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Specifics,\n",
    "\n",
    "# Location on disk of the dataset to generate contextual embeddings from.\n",
    "DATA_FILE_PATH = \"dataset.txt\"\n",
    "\n",
    "# Location on disk of the glove vocabulary dataset, used when generating word embeddings.\n",
    "GLOVE_FILE_PATH = \"glove.6B.300d-vocabulary.txt\"\n",
    "\n",
    "# Max number of sentences used when generating contextualized embeddings.\n",
    "MAX_SENTENCES = 250_000\n",
    "\n",
    "# Max number of tokens per sentence. Extra tokens are truncated. Sentences with less than this many tokens are padded.\n",
    "MAX_TOKENIZATION_LENGTH = 200\n",
    "\n",
    "# Size of batches to process on the GPU in parrellel while generating embeddings.\n",
    "BATCH_SIZE = 350\n",
    "\n",
    "## Model Specifcs,\n",
    "\n",
    "# Model name, only accepts valid roberta models\n",
    "MODEL = \"roberta-base\"\n",
    "\n",
    "# The embedding size used by the model (assign based on the model your using!)\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "# Set of tokens to ignore\n",
    "EMBEDDING_TOKEN_IGNORE_SET = {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821fb0a-89e7-44e2-a925-e2b12ac9b3b2",
   "metadata": {},
   "source": [
    "## Data Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb98247-e9f4-4a9d-99c0-345246b40543",
   "metadata": {},
   "source": [
    "Load in the dataset, sentence by sentence, into the global array `sentences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c245daa-814e-4b8a-9b12-ebd4cecc0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4468825 lines and 47820302 words.\n",
      "Average length: 67.34097665493726\n",
      "Max length: 3263\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "linecount = 0\n",
    "wordcount = 0 \n",
    "\n",
    "lengths = []\n",
    "\n",
    "with open(DATA_FILE_PATH, 'r') as dataset_file:\n",
    "    while line := dataset_file.readline():\n",
    "        sentences += [line]\n",
    "        linecount += 1\n",
    "        wordcount += len(line.split())\n",
    "        lengths += [len(line)]\n",
    "\n",
    "print(\"Loaded \" + str(linecount) + \" lines and \" + str(wordcount) + \" words.\")\n",
    "print(\"Average length: \" + str(np.average(lengths)))\n",
    "print(\"Max length: \" + str(np.max(lengths)))\n",
    "\n",
    "sentences = sentences[:MAX_SENTENCES]\n",
    "sentence_count = len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4d75c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46400f",
   "metadata": {},
   "source": [
    "We'll be handling tokenization in the Dataset prior to training time to avoid issues with memory leaks related to batch iterations. See this [github](https://github.com/pytorch/pytorch/issues/13246) issue for more information. Datasets are used to take advantage of the DataLoader and its auto batching features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a70e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaDataset(Dataset):\n",
    "\tdef __init__(self, sentences: list, max_length: int):\n",
    "\t\tsentences_tokenized = []\n",
    "\n",
    "\t\tfor sentence in sentences:\n",
    "\t\t\ttokens = tokenizer.encode_plus(sentence, padding = \"max_length\", max_length = max_length, truncation = True, return_tensors='pt')\n",
    "\t\t\t\n",
    "\t\t\tids = torch.LongTensor(tokens['input_ids'][0])\n",
    "\t\t\tmask = torch.LongTensor(tokens['attention_mask'][0]) \n",
    "\n",
    "\t\t\tsentences_tokenized += [np.array([ids, mask])]\n",
    "\n",
    "\t\t\tprint(f\"{len(sentences_tokenized) / len(sentences) * 100.0}% complete.\\t\\t\\t\", end ='\\r')\n",
    "\n",
    "\t\tself.sentences_tokenized = np.array(sentences_tokenized)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.sentences_tokenized)\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn (self.sentences_tokenized[index][0], self.sentences_tokenized[index][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb3a6a",
   "metadata": {},
   "source": [
    "Initialize the tokenizer, we'll be using the RobertaTokenzierFast for performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bfc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"FacebookAI/roberta-base\", add_prefix_space = True, clean_up_tokenization_spaces = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ad6c5",
   "metadata": {},
   "source": [
    "Initialize the Dataset & DataLoader (will take a couple minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73684ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% complete.\t\t\t\t\tmplete.\t\t\t\t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "dataset = RobertaDataset(sentences, MAX_TOKENIZATION_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5210ae",
   "metadata": {},
   "source": [
    "## Embedding Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137620ff-40ae-4ba6-8874-86e576bfdb6d",
   "metadata": {},
   "source": [
    "Setup the model and load it on the compute device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f22c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(MODEL).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d7db6",
   "metadata": {},
   "source": [
    "Calculate cumulative embeddings, batch by batch, from the dataset. For every token, the sum of its embeddings is calculated (`token_to_embedding_sums`) and a tally of the number of times the token occures is kept (token_to_embedding_counts). After all batches are processed, the embedding is divided by the number of times it occured to get an average value per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5eb7cbd-4083-4edb-902f-b1cd61bd8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.1% complete. 14.1% RAM utilization. \t\t\tization. \t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "token_size = tokenizer.vocab_size\n",
    "\n",
    "token_to_embedding_sums = np.zeros((token_size, EMBEDDING_SIZE))\n",
    "token_to_embedding_counts = np.zeros((token_size, 1))\n",
    "\n",
    "processed_tokens = 0;\n",
    "\n",
    "def calculate_embeddings(model) -> dict:\n",
    "\tprocessed_sentances = 0\n",
    "\t\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\ttoken_to_avg_embedding_map = {}\n",
    "\tavg_token_embedding = None\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch in dataloader:\n",
    "\t\t\t\n",
    "\t\t\tids = batch[0].to(device)\n",
    "\t\t\tmask = batch[1].to(device)\n",
    "\t\t\t\n",
    "\t\t\toutput = model(ids, mask)\n",
    "\t\n",
    "\t\t\t####################################################################\n",
    "\t\t\n",
    "\t\t\t### shape, [batch, tokens in sentance, embeddings of each token]\n",
    "\t\t\tembeddings = output[0].detach().cpu().numpy()\n",
    "\t\t\t\n",
    "\t\t\t# Update average embeddings, \n",
    "\t\t\tfor sentence_embedding_index in range(len(embeddings)):\n",
    "\t\t\t\tsentence_embedding = embeddings[sentence_embedding_index]\n",
    "\t\n",
    "\t\t\t\tfor token_index in range(len(sentence_embedding)):\n",
    "\t\t\t\t\ttoken = ids[sentence_embedding_index][token_index]\n",
    "\t\t\t\t\ttoken_to_embedding_sums[token] += sentence_embedding[token_index]\n",
    "\t\t\t\t\ttoken_to_embedding_counts[token] += 1\n",
    "\n",
    "\t\t\tpct_virt_ram = psutil.virtual_memory().percent\n",
    "\t\t\tprocessed_sentances += BATCH_SIZE\n",
    "\t\t\tpct_complete = processed_sentances / (sentence_count) * 100.0 \n",
    "\n",
    "\t\t\tif (pct_virt_ram) > 90.0:\n",
    "\t\t\t\tprint(\"Aborting embedding generation early to avoid running out of RAM!\")\n",
    "\t\t\t\tprint(f\"{pct_complete}% complete. {pct_virt_ram}% RAM utilization. \\t\\t\\t\", end ='\\r')\n",
    "\t\t\t\tprint(f\"{psutil.virtual_memory().used / 1e9} GB used.\")\n",
    "\t\t\t\treturn token_to_avg_embedding_map, avg_token_embedding\n",
    "\t\t\t\n",
    "\t\t\tprint(f\"{pct_complete}% complete. {pct_virt_ram}% RAM utilization. \\t\\t\\t\", end ='\\r')\n",
    "\t\t\t\n",
    "\treturn token_to_avg_embedding_map, avg_token_embedding\n",
    "\n",
    "token_to_avg_embedding_map, avg_token_embedding = calculate_embeddings(model)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b878e",
   "metadata": {},
   "source": [
    "Finish up embedding calculations. Calculate the average embedding per token (`token_to_embedding_averages`) and the global average token (`average_embedding`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6cf766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_embedding_averages = np.zeros((token_size, EMBEDDING_SIZE))\n",
    "average_embedding = np.sum(token_to_embedding_sums, axis=0) / np.sum(token_to_embedding_counts)\n",
    "\n",
    "token_to_embedding_counts[token_to_embedding_counts == 0] = 1\n",
    "token_to_embedding_averages = token_to_embedding_sums / token_to_embedding_counts\n",
    "\n",
    "# set all un-encountered tokens to 0\n",
    "# would be worth looking into the effects of using the average token here!\n",
    "token_to_embedding_averages[np.sum(token_to_embedding_averages) == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae4684",
   "metadata": {},
   "source": [
    "## Problem One Complete.\n",
    "The `token_to_embedding_averages` matrix contains a mapping between sub-word tokens and their average embedding in the dataset. \n",
    "\n",
    "e.g. \n",
    "\n",
    "```\n",
    "TOKEN_EMBEDDING = token_to_embedding_averages[TOKEN]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f5629",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "This section implements the `most_similar()` functions from chapter 9 and tests them using the specified examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72312c",
   "metadata": {},
   "source": [
    "Generate word to embedding mappings (`word_to_embedding`) for the contents of the glove vocabulary file (`GLOVE_FILE_PATH`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6827696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_embedding(word):\n",
    "\ttokens = tokenizer.encode_plus(word, padding = \"max_length\", max_length = MAX_TOKENIZATION_LENGTH, truncation = True)['input_ids']\n",
    "\ttokens = np.array(tokens) \n",
    "\n",
    "\tembedding = np.zeros(EMBEDDING_SIZE)\n",
    "\ttoken_count = 0\n",
    "\tfor token in tokens:\n",
    "\t\tif token not in EMBEDDING_TOKEN_IGNORE_SET: \n",
    "\t\t\tembedding += token_to_embedding_averages[token]\t\n",
    "\t\t\ttoken_count += 1\n",
    "\treturn embedding / token_count\n",
    "\n",
    "\n",
    "def generate_word_embedding_map(words: list) -> dict:\n",
    "\tword_embedding_map = {}\n",
    "\tprocessed_words = 0\n",
    "\tfor word in words:\n",
    "\t\tembedding = get_average_embedding(word)\n",
    "\t\tword_embedding_map[word] = embedding\n",
    "\t\n",
    "\t\tprocessed_words += 1\n",
    "\t\tprint(f\"{processed_words / len(words) * 100.0}% complete. {len(word_embedding_map)} word embeddings generated.\\t\\t\\t\", end ='\\r')\n",
    "\treturn word_embedding_map\n",
    "\n",
    "\n",
    "def load_words(from_file: str) -> list:\n",
    "\twords = []\n",
    "\twith open(from_file, 'r') as file:\n",
    "\t\twhile line := file.readline():\n",
    "\t\t\twords += [line.strip()]\n",
    "\n",
    "\treturn words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06d6dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% complete. 400000 word embeddings generated.\t\t\tenerated.\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "words = load_words(GLOVE_FILE_PATH)\n",
    "word_to_embedding = generate_word_embedding_map(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0398a",
   "metadata": {},
   "source": [
    "Implement the `most_similar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0a61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word):\n",
    "    if word in word_to_embedding:\n",
    "        emb = word_to_embedding[word]\n",
    "    else:\n",
    "        emb = get_average_embedding(word)\n",
    "        word_to_embedding[word] = emb\n",
    "    return emb\n",
    "\n",
    "def most_similar(word, topn=10):\n",
    "    emb = get_word_embedding(word)\n",
    "\n",
    "    # calculate similarities to all words in our vocabulary\n",
    "    similarities = []\n",
    "    for word, embedding, in word_to_embedding.items():\n",
    "        similarity = embedding @ emb\n",
    "\n",
    "        similarities += [(float(similarity), str(word))]\n",
    "\n",
    "    similarities.sort(key = itemgetter(0))\n",
    "    similarities.reverse()\n",
    "    \n",
    "    return similarities[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ee1ad",
   "metadata": {},
   "source": [
    "## 6 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c52c9ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(131.35084119944005, 'higher-dimensional'),\n",
       " (131.3331053641163, 'one-dimensional'),\n",
       " (131.33226782229394, 'best-kept'),\n",
       " (131.16419286968562, 'human-animal'),\n",
       " (131.1133371650292, 'near-earth-object'),\n",
       " (131.0245007210086, 'other-dimensional'),\n",
       " (130.9287293293737, 'high-dimensional'),\n",
       " (130.7789125005217, 'use-value'),\n",
       " (130.72282521956038, 'writer-editor'),\n",
       " (130.60795817867975, 'part-owner')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"cactus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c72b0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39.20734567809385, 'moslems'),\n",
       " (39.20734567809385, 'beholder'),\n",
       " (39.20734567809385, '----------------------------------------------'),\n",
       " (39.20734567809385, 'ghouls'),\n",
       " (39.20734567809385, 'disobedient'),\n",
       " (39.20734567809385, 'reimburses'),\n",
       " (39.20734567809385, 'orgasms'),\n",
       " (39.20734567809385, '------------------------------------------------'),\n",
       " (39.20734567809385, 'relearning'),\n",
       " (39.20734567809385, '!!!!!')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8a83d98-c0b3-405e-8de9-e21af3181d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39.80380926749184, 'moslems'),\n",
       " (39.80380926749184, 'beholder'),\n",
       " (39.80380926749184, '----------------------------------------------'),\n",
       " (39.80380926749184, 'ghouls'),\n",
       " (39.80380926749184, 'disobedient'),\n",
       " (39.80380926749184, 'reimburses'),\n",
       " (39.80380926749184, 'orgasms'),\n",
       " (39.80380926749184, '------------------------------------------------'),\n",
       " (39.80380926749184, 'relearning'),\n",
       " (39.80380926749184, '!!!!!')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"Angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aca78ffe-22e4-46c2-9907-56beae22631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(38.45007287102884, 'moslems'),\n",
       " (38.45007287102884, 'beholder'),\n",
       " (38.45007287102884, '----------------------------------------------'),\n",
       " (38.45007287102884, 'ghouls'),\n",
       " (38.45007287102884, 'disobedient'),\n",
       " (38.45007287102884, 'reimburses'),\n",
       " (38.45007287102884, 'orgasms'),\n",
       " (38.45007287102884, '------------------------------------------------'),\n",
       " (38.45007287102884, 'relearning'),\n",
       " (38.45007287102884, '!!!!!')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"quickly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2232ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(141.83930279848408, 'higher-dimensional'),\n",
       " (141.6022133899604, 'one-dimensional'),\n",
       " (141.13505233585803, 'other-dimensional'),\n",
       " (140.92190495429995, 'use-value'),\n",
       " (140.781117957326, 'part-owner'),\n",
       " (140.6535624685956, 'best-kept'),\n",
       " (140.65225236056526, 'high-dimensional'),\n",
       " (140.62948610969406, 'near-earth-object'),\n",
       " (140.2567879639438, 'part-time'),\n",
       " (140.25607619236177, 'low-dimensional')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"between\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "204a5c29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'most_similar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m most_similar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'most_similar' is not defined"
     ]
    }
   ],
   "source": [
    "most_similar(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8077417e",
   "metadata": {},
   "source": [
    "## Problem Two Complete."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs396",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
