{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216965d0-503f-4267-9420-ee2cb6c130e8",
   "metadata": {},
   "source": [
    "# Assignment 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e382b",
   "metadata": {},
   "source": [
    "This notebook uses Roberta to generate static embeddings for words with 768d averaged contextual embeddings. Contextual embeddings are calculated using the provided `dataset.txt`. Ensure the file `dataset.txt` is placed in the directory as this notebook before running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e2746e-2836-44b9-8422-33ad1d30d0b7",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f874bd9-a81e-419a-9ee5-2731ef1cafd1",
   "metadata": {},
   "source": [
    "Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d805de2-295a-485c-abeb-d253c9c7e1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import psutil\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# RobertaModel and Tokenizer\n",
    "from transformers import RobertaModel, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70527ac9-3e10-41d0-8ffa-03eefbe50ffd",
   "metadata": {},
   "source": [
    "Initialize environment compute device (GPU or CPU depending on whats avalible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e09e291-92dd-4179-9ded-72c95279a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "random seed: 1234\n"
     ]
    }
   ],
   "source": [
    "# enable tqdm in pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# set to True to use the gpu (if there is one available)\n",
    "use_gpu = True\n",
    "\n",
    "# select device\n",
    "device = torch.device('cuda' if use_gpu and torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device.type}')\n",
    "\n",
    "# random seed\n",
    "seed = 1234\n",
    "\n",
    "# set random seed\n",
    "if seed is not None:\n",
    "    print(f'random seed: {seed}')\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a551ea27",
   "metadata": {},
   "source": [
    "Initalize global constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Specifics,\n",
    "\n",
    "# Location on disk of the dataset to generate contextual embeddings from.\n",
    "DATA_FILE_PATH = \"dataset.txt\"\n",
    "\n",
    "# Location on disk of the glove vocabulary dataset, used when generating word embeddings.\n",
    "GLOVE_FILE_PATH = \"glove.6B.300d-vocabulary.txt\"\n",
    "\n",
    "# Max number of sentences used when generating contextualized embeddings.\n",
    "MAX_SENTENCES = 5_000\n",
    "\n",
    "# Max number of tokens per sentence. Extra tokens are truncated. Sentences with less than this many tokens are padded.\n",
    "MAX_TOKENIZATION_LENGTH = 200\n",
    "\n",
    "# Size of batches to process on the GPU in parrellel while generating embeddings.\n",
    "BATCH_SIZE = 350\n",
    "\n",
    "## Model Specifcs,\n",
    "\n",
    "# Model name, only accepts valid roberta models\n",
    "MODEL = \"roberta-base\"\n",
    "\n",
    "# The embedding size used by the model (assign based on the model your using!)\n",
    "EMBEDDING_SIZE = 768\n",
    "\n",
    "# Set of tokens to ignore\n",
    "EMBEDDING_TOKEN_IGNORE_SET = {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9821fb0a-89e7-44e2-a925-e2b12ac9b3b2",
   "metadata": {},
   "source": [
    "## Data Pre-Processing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb98247-e9f4-4a9d-99c0-345246b40543",
   "metadata": {},
   "source": [
    "Load in the dataset, sentence by sentence, into the global array `sentences`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c245daa-814e-4b8a-9b12-ebd4cecc0d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4468825 lines and 47820302 words.\n",
      "Average length: 67.34097665493726\n",
      "Max length: 3263\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "linecount = 0\n",
    "wordcount = 0 \n",
    "\n",
    "lengths = []\n",
    "\n",
    "with open(DATA_FILE_PATH, 'r') as dataset_file:\n",
    "    while line := dataset_file.readline():\n",
    "        sentences += [line]\n",
    "        linecount += 1\n",
    "        wordcount += len(line.split())\n",
    "        lengths += [len(line)]\n",
    "\n",
    "print(\"Loaded \" + str(linecount) + \" lines and \" + str(wordcount) + \" words.\")\n",
    "print(\"Average length: \" + str(np.average(lengths)))\n",
    "print(\"Max length: \" + str(np.max(lengths)))\n",
    "\n",
    "sentences = sentences[:MAX_SENTENCES]\n",
    "sentence_count = len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4d75c",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46400f",
   "metadata": {},
   "source": [
    "We'll be handling tokenization in the Dataset prior to training time to avoid issues with memory leaks related to batch iterations. See this [github](https://github.com/pytorch/pytorch/issues/13246) issue for more information. Datasets are used to take advantage of the DataLoader and its auto batching features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a70e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class RobertaDataset(Dataset):\n",
    "\tdef __init__(self, sentences: list, max_length: int):\n",
    "\t\tsentences_tokenized = []\n",
    "\n",
    "\t\tfor sentence in sentences:\n",
    "\t\t\ttokens = tokenizer.encode_plus(sentence, padding = \"max_length\", max_length = max_length, truncation = True, return_tensors='pt')\n",
    "\t\t\t\n",
    "\t\t\tids = torch.LongTensor(tokens['input_ids'][0])\n",
    "\t\t\tmask = torch.LongTensor(tokens['attention_mask'][0]) \n",
    "\n",
    "\t\t\tsentences_tokenized += [np.array([ids, mask])]\n",
    "\n",
    "\t\t\tprint(f\"{len(sentences_tokenized) / len(sentences) * 100.0}% complete.\\t\\t\\t\", end ='\\r')\n",
    "\n",
    "\t\tself.sentences_tokenized = np.array(sentences_tokenized)\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.sentences_tokenized)\n",
    "\t\n",
    "\tdef __getitem__(self, index):\n",
    "\t\treturn (self.sentences_tokenized[index][0], self.sentences_tokenized[index][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb3a6a",
   "metadata": {},
   "source": [
    "Initialize the tokenizer, we'll be using the RobertaTokenzierFast for performance reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94bfc857",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"FacebookAI/roberta-base\", add_prefix_space = True, clean_up_tokenization_spaces = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93ad6c5",
   "metadata": {},
   "source": [
    "Initialize the Dataset & DataLoader (will take a couple minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73684ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% complete.\t\t\tcomplete.\t\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "dataset = RobertaDataset(sentences, MAX_TOKENIZATION_LENGTH)\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5210ae",
   "metadata": {},
   "source": [
    "## Embedding Calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137620ff-40ae-4ba6-8874-86e576bfdb6d",
   "metadata": {},
   "source": [
    "Setup the model and load it on the compute device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f22c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(MODEL).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d7db6",
   "metadata": {},
   "source": [
    "Calculate cumulative embeddings, batch by batch, from the dataset. For every token, the sum of its embeddings is calculated (`token_to_embedding_sums`) and a tally of the number of times the token occures is kept (token_to_embedding_counts). After all batches are processed, the embedding is divided by the number of times it occured to get an average value per token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb7cbd-4083-4edb-902f-b1cd61bd8b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105.0% complete. 10.7% RAM utilization. \t\t\tization. \t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "token_size = tokenizer.vocab_size\n",
    "\n",
    "token_to_embedding_sums = np.zeros((token_size, EMBEDDING_SIZE))\n",
    "token_to_embedding_counts = np.zeros((token_size, 1))\n",
    "\n",
    "processed_tokens = 0;\n",
    "\n",
    "def calculate_embeddings(model) -> dict:\n",
    "\tprocessed_sentances = 0\n",
    "\t\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\ttoken_to_avg_embedding_map = {}\n",
    "\tavg_token_embedding = None\n",
    "\t\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch in dataloader:\n",
    "\t\t\t\n",
    "\t\t\tids = batch[0].to(device)\n",
    "\t\t\tmask = batch[1].to(device)\n",
    "\t\t\t\n",
    "\t\t\toutput = model(ids, mask)\n",
    "\t\n",
    "\t\t\t####################################################################\n",
    "\t\t\n",
    "\t\t\t### shape, [batch, tokens in sentance, embeddings of each token]\n",
    "\t\t\tembeddings = output[0].detach().cpu().numpy()\n",
    "\t\t\t\n",
    "\t\t\t# Update average embeddings, \n",
    "\t\t\tfor sentence_embedding_index in range(len(embeddings)):\n",
    "\t\t\t\tsentence_embedding = embeddings[sentence_embedding_index]\n",
    "\t\n",
    "\t\t\t\tfor token_index in range(len(sentence_embedding)):\n",
    "\t\t\t\t\ttoken = ids[sentence_embedding_index][token_index]\n",
    "\t\t\t\t\ttoken_to_embedding_sums[token] += sentence_embedding[token_index]\n",
    "\t\t\t\t\ttoken_to_embedding_counts[token] += 1\n",
    "\n",
    "\t\t\tpct_virt_ram = psutil.virtual_memory().percent\n",
    "\t\t\tprocessed_sentances += BATCH_SIZE\n",
    "\t\t\tpct_complete = processed_sentances / (sentence_count) * 100.0 \n",
    "\n",
    "\t\t\tif (pct_virt_ram) > 90.0:\n",
    "\t\t\t\tprint(\"Aborting embedding generation early to avoid running out of RAM!\")\n",
    "\t\t\t\tprint(f\"{pct_complete}% complete. {pct_virt_ram}% RAM utilization. \\t\\t\\t\", end ='\\r')\n",
    "\t\t\t\tprint(f\"{psutil.virtual_memory().used / 1e9} GB used.\")\n",
    "\t\t\t\treturn token_to_avg_embedding_map, avg_token_embedding\n",
    "\t\t\t\n",
    "\t\t\tprint(f\"{pct_complete}% complete. {pct_virt_ram}% RAM utilization. \\t\\t\\t\", end ='\\r')\n",
    "\t\t\t\n",
    "\treturn token_to_avg_embedding_map, avg_token_embedding\n",
    "\n",
    "token_to_avg_embedding_map, avg_token_embedding = calculate_embeddings(model)\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714b878e",
   "metadata": {},
   "source": [
    "Finish up embedding calculations. Calculate the average embedding per token (`token_to_embedding_averages`) and the global average token (`average_embedding`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_embedding_averages = np.zeros((token_size, EMBEDDING_SIZE))\n",
    "average_embedding = np.sum(token_to_embedding_sums, axis=0) / np.sum(token_to_embedding_counts)\n",
    "\n",
    "token_to_embedding_counts[token_to_embedding_counts == 0] = 1\n",
    "token_to_embedding_averages = token_to_embedding_sums / token_to_embedding_counts\n",
    "\n",
    "# set all un-encountered tokens to 0\n",
    "# would be worth looking into the effects of using the average token here!\n",
    "token_to_embedding_averages[np.sum(token_to_embedding_averages) == 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ae4684",
   "metadata": {},
   "source": [
    "# Problem One Complete.\n",
    "The `token_to_embedding_averages` matrix contains a mapping between sub-word tokens and their average embedding in the dataset. \n",
    "\n",
    "e.g. \n",
    "\n",
    "```\n",
    "TOKEN_EMBEDDING = token_to_embedding_averages[TOKEN]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f5629",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "This section implements the `most_similar()` functions from chapter 9 and tests them using the specified examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72312c",
   "metadata": {},
   "source": [
    "Generate word to embedding mappings (`word_to_embedding`) for the contents of the glove vocabulary file (`GLOVE_FILE_PATH`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6827696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_embedding(word):\n",
    "\ttokens = tokenizer.encode_plus(word, padding = \"max_length\", max_length = MAX_TOKENIZATION_LENGTH, truncation = True)['input_ids']\n",
    "\ttokens = np.array(tokens) \n",
    "\n",
    "\tembedding = np.zeros(EMBEDDING_SIZE)\n",
    "\ttoken_count = 0\n",
    "\tfor token in tokens:\n",
    "\t\tif token not in EMBEDDING_TOKEN_IGNORE_SET: \n",
    "\t\t\tembedding += token_to_embedding_averages[token]\t\n",
    "\t\t\ttoken_count += 1\n",
    "\treturn embedding / token_count\n",
    "\n",
    "\n",
    "def generate_word_embedding_map(words: list) -> dict:\n",
    "\tword_embedding_map = {}\n",
    "\tprocessed_words = 0\n",
    "\tfor word in words:\n",
    "\t\tembedding = get_average_embedding(word)\n",
    "\t\tword_embedding_map[word] = embedding\n",
    "\t\n",
    "\t\tprocessed_words += 1\n",
    "\t\tprint(f\"{processed_words / len(words) * 100.0}% complete. {len(word_embedding_map)} word embeddings generated.\\t\\t\\t\", end ='\\r')\n",
    "\treturn word_embedding_map\n",
    "\n",
    "\n",
    "def load_words(from_file: str) -> list:\n",
    "\twords = []\n",
    "\twith open(from_file, 'r') as file:\n",
    "\t\twhile line := file.readline():\n",
    "\t\t\twords += [line.strip()]\n",
    "\n",
    "\treturn words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% complete. 400000 word embeddings generated.\t\t\tenerated.\t\t\t\t\r"
     ]
    }
   ],
   "source": [
    "words = load_words(GLOVE_FILE_PATH)\n",
    "word_to_embedding = generate_word_embedding_map(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0398a",
   "metadata": {},
   "source": [
    "Implement the `most_similar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb0a61b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(word):\n",
    "    if word in word_to_embedding:\n",
    "        emb = word_to_embedding[word]\n",
    "    else:\n",
    "        emb = get_average_embedding(word)\n",
    "        word_to_embedding[word] = emb\n",
    "    return emb\n",
    "\n",
    "def most_similar(word, topn=10):\n",
    "    emb = get_word_embedding(word)\n",
    "\n",
    "    # calculate similarities to all words in our vocabulary\n",
    "    similarities = []\n",
    "    for word, embedding, in word_to_embedding.items():\n",
    "        similarity = embedding @ emb\n",
    "\n",
    "        similarities += [(float(similarity), str(word))]\n",
    "\n",
    "    similarities.sort(key = itemgetter(0))\n",
    "    similarities.reverse()\n",
    "    \n",
    "    return similarities[:topn]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212ee1ad",
   "metadata": {},
   "source": [
    "## 6 Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c52c9ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(94.54114162876064, 'thing'),\n",
       " (92.46924291358405, 'humanlike'),\n",
       " (91.83680549440035, 'human-like'),\n",
       " (91.23792409760661, 'pathogen'),\n",
       " (91.22880900882276, 'vs'),\n",
       " (91.02853194538777, 'thingyan'),\n",
       " (90.76023096769799, 'human-made'),\n",
       " (90.39873212794556, 'space-like'),\n",
       " (90.32766943072517, 'disk-like'),\n",
       " (90.23504644240433, 'time-like')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"cactus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c72b0d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(70.3473327344818, 'thing'),\n",
       " (68.00940945947434, 'vs'),\n",
       " (66.92688627566939, 'vs.'),\n",
       " (66.60493417459438, 'bory'),\n",
       " (66.55009068172089, 'qms'),\n",
       " (66.35938995237177, 'bms'),\n",
       " (66.3425016755433, 'humanlike'),\n",
       " (66.30992984724817, 'pathogen'),\n",
       " (66.09877035790078, 'bogen'),\n",
       " (65.80931234613257, 'st')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"cake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a83d98-c0b3-405e-8de9-e21af3181d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(142.84085103066718, 'thing'),\n",
       " (139.54487719380904, 'humanlike'),\n",
       " (138.3806077986585, 'human-like'),\n",
       " (138.3380004026888, 'thingyan'),\n",
       " (137.53724436952353, 'childlike'),\n",
       " (137.07903831446652, 'time-like'),\n",
       " (136.93184687692906, 'human-made'),\n",
       " (136.87488318044439, 'child-like'),\n",
       " (136.83798866209236, 'sure'),\n",
       " (136.55667626361523, 'vs')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"angry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aca78ffe-22e4-46c2-9907-56beae22631c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(140.3715959131064, 'thing'),\n",
       " (136.14570874025827, 'humanlike'),\n",
       " (135.23933838887217, 'thingyan'),\n",
       " (135.14198260838916, 'human-like'),\n",
       " (134.08463450033133, 'pathogen'),\n",
       " (133.5983443347207, 'highly'),\n",
       " (133.52284516000404, 'childlike'),\n",
       " (133.49631987865257, 'space-like'),\n",
       " (133.39948909063173, 'human-made'),\n",
       " (133.39365969914846, 'time-like')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"quickly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2232ec40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(148.74784660289092, 'thing'),\n",
       " (145.87001635383118, 'humanlike'),\n",
       " (145.00810886668032, 'human-like'),\n",
       " (143.9097701373302, 'human-made'),\n",
       " (143.74316671056937, 'thingyan'),\n",
       " (143.18988685153795, 'space-like'),\n",
       " (143.0281233136547, 'time-like'),\n",
       " (143.0098677819803, 'affectations'),\n",
       " (142.64357965492877, 'perms'),\n",
       " (142.3691115317179, 'highly')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"between\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "204a5c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(155.75355788958524, 'thing'),\n",
       " (150.69659942193294, 'humanlike'),\n",
       " (149.24642787338888, 'thingyan'),\n",
       " (148.9029581677132, 'human-like'),\n",
       " (147.4101672199146, 'vs'),\n",
       " (147.21976671099344, 'things'),\n",
       " (147.10098644255157, 'pathogen'),\n",
       " (146.947258151575, 'space-like'),\n",
       " (146.8439232080075, 'bory'),\n",
       " (146.53961986324157, 'human-made')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar(\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8adb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81126e70-c9ea-44d7-8f8e-55c3b872e1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs396",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
